# 全体を通してのメモ

## RWPについて

- pose_timeはモデルの交換を行ってから各ノードが学習するために必要な時間を取るためだと考えられるが、現状そうはなっていない->rwp/generate.pyを変える必要？
- 現状の実装では、モデルの交換をしてから各ノードが自前のデータで十分な時間学習するといったことはなく、モデルの交換を特定の相手と絶えず行いながら一定時間学習するようなイメージ
- radio range=100なら1辺500の領域だとほぼ全てに出会ってしまってよくないかも
- 毎回合わせるノードの数を減らした方が性能的にも、検証目的にもいい気がする

## ファインチューニングについて

- vggだとパラメータ多すぎてメモリがきつい
- 現実的なのはmobilinet or resnet

## subsetのそれぞれに別のtransformをやる場合

- 単純にsubsetの1つをtransferLearning.pyを使って学習したが、うまくいかない
- データ数が足りない説
- train_accが張り付いてるからそんなことなさそう
- train_transformのnormalizeが悪さしてた -> tensorからtapleにしましょう
- そもそも転移学習だけでなく、いろいろな他のパラメータ削減の手法を考えてみるのもアリ

## contact patternについて

- パラメータ交換を行っているノードと分かれてしまうと、徐々にそのノードの情報は失われてしまう
- ということは極端な話、一度であったノードとは交換し続けた方がいい？
- 例えば一定時間あるノードと交換を行い、1つ前の交換終了時のパラメータを保持しておいて混ぜるとかは？
- こうすれば影響残せそうだし、かつトラフィックもそこまで大きくない
- とりあえず、全てのノードが常に交換可能な場合で検証してみる

### mobilenetでの性能比較

- 2023-06-24-16, 2023-06-24-21, 2023-06-25-00で比較。
- contact_patternのpose以外の条件は固定

#### accの推移について

- 学習の遷移がposeが大きくなるほど遅くなる。また、ギザギザが大きくなる。
- 性能については色々なノードに合っていると考えられるp小の方が高そうな見た目にはなった。
- 最も多くのノードの出会いが起きているはずのp=10の精度のばらつきがすごく大きかった。可能性の1つとしてノードと出会って交換が不十分であるためにこうなっている可能性もある。
- これについては、p大のものたちももっとepochを増やすとこうなる可能性もある。

#### cmについて

- aa

## pre_trainについて

- optimizerをpretrainとtrainで分けた方が良くない？ -> 分けた

## 使用するモデルについて

- vggよりもmobilenetの方が性能が高い傾向にあり、その度合いはWAFLにすると顕著
- -> 学習データが少ないと深いモデルの表層部分をそのタスクに合わせることができない？
- つまり、vggで達成するにはデータ数がもっと必要？
- あるいは、vggの方が複雑で深いから過学習気味
- トレーニングデータの精度が比較的低い部分で頭打ちなのはモデルの混ぜ込みによる効果があるから当然
- 今ぐらいの90%とかでも実は過学習している説もある
- もっと長い混ぜ込みがいる？とりあえず、p40とかで実験してみる

## lrについて

- contact file: rwp_n10_a0500_r100_p10_s01.json、filter file: なしにおいてlrを変化(0.005, 0.01)させると、大きくするほど最後の方のtrainのブレが減った
- おそらくこのブレは交換によって起きているため、lrが大きいほどすぐに戻ってブレが小さくなる
- lrが大きいと一度に全てのノードと出会わない場合には、出会っていなかったノードの情報を忘れてしまう
- そもそもtrainのブレが小さいのはval_accが高くない限りは望ましくない
- 交換しても過学習から抜け出せなくなってしまう。
- valの方の振れ幅はほとんど変わらない
- 結局、どの程度もらったモデルの性質を残すかになるので、コンタクトパターンに依存しそう

## transformのGPUへの移行

- おそらく遅いのはCPU側のランキューが長くて、割り当てまでが長いせいっぽい -> GPU2サーバが混んでるだけ？
- resize済みデータをGPUメモリにおいていると早い
- GPUメモリ上にデータを置かずにGPUを使わない方法は使わない

## transformについて
- WAFLの方が性能がいいがもしかしたらnormalizeの規模感が変わった影響があるかもしれない
- centralizeの場合で、10個に分けてそれぞれで求めた平均とかを使ってnormalizeした上で、学習させる必要あり？
